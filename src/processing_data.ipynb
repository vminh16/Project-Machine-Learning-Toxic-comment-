{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "6e164bae",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Số lượng dòng: 164069\n",
      "\n",
      "Các cột: ['text', 'label', 'source', 'language']\n",
      "\n",
      "Thông tin chi tiết:\n",
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 164069 entries, 0 to 164068\n",
      "Data columns (total 4 columns):\n",
      " #   Column    Non-Null Count   Dtype \n",
      "---  ------    --------------   ----- \n",
      " 0   text      164069 non-null  object\n",
      " 1   label     164069 non-null  int64 \n",
      " 2   source    164069 non-null  object\n",
      " 3   language  164069 non-null  object\n",
      "dtypes: int64(1), object(3)\n",
      "memory usage: 5.0+ MB\n",
      "None\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "# Load dữ liệu\n",
    "df = pd.read_csv('../data/merged_dataset.csv')\n",
    "\n",
    "# Xem thông tin cơ bản\n",
    "print(f\"Số lượng dòng: {len(df)}\")\n",
    "print(f\"\\nCác cột: {df.columns.tolist()}\")\n",
    "print(f\"\\nThông tin chi tiết:\")\n",
    "print(df.info())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "59b50d55",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                                                text  label  source language\n",
      "0  Explanation\\nWhy the edits made under my usern...      0  jigsaw       en\n",
      "1  D'aww! He matches this background colour I'm s...      0  jigsaw       en\n",
      "2  Hey man, I'm really not trying to edit war. It...      0  jigsaw       en\n",
      "3  \"\\nMore\\nI can't make any real suggestions on ...      0  jigsaw       en\n",
      "4  You, sir, are my hero. Any chance you remember...      0  jigsaw       en\n",
      "                                                     text  label  source  \\\n",
      "47398   \"\\n\\nEach in turn\\n\\nSuggested: In physics, fo...      0  jigsaw   \n",
      "103425                 REDIRECT Talk:Pedro Daniel Estrada      0  jigsaw   \n",
      "127904  Why to go buddy! So how is Nancy holding up?\\n...      1  jigsaw   \n",
      "70185   \"\\n No, not phosphorescent. Phosphorescence, a...      0  jigsaw   \n",
      "36426   HELP \\n\\nHEY BUDDY I DON'T LIKE AT ALL!!!  \\n\\...      0  jigsaw   \n",
      "\n",
      "       language  \n",
      "47398        en  \n",
      "103425       en  \n",
      "127904       en  \n",
      "70185        en  \n",
      "36426        en  \n",
      "\n",
      "Số lượng comments tiếng Việt: 4498\n",
      "                                                     text  label   source  \\\n",
      "161780  Thuong la 1 ten qua toi ky luat qua nhe , can ...      0  youtube   \n",
      "163297  Diễn thì do mà cu doi co hao quang này no rồi ...      1  youtube   \n",
      "163152  Binz rất là lành tính, đón nhận mọi điều rất n...      0  youtube   \n",
      "\n",
      "       language  \n",
      "161780       vi  \n",
      "163297       vi  \n",
      "163152       vi  \n"
     ]
    }
   ],
   "source": [
    "# Xem 5 dòng đầu\n",
    "print(df.head())\n",
    "\n",
    "# Xem ngẫu nhiên 5 dòng\n",
    "print(df.sample(5))\n",
    "\n",
    "# Xem riêng dữ liệu tiếng Việt\n",
    "vietnamese_df = df[df['language'] == 'vi']\n",
    "print(f\"\\nSố lượng comments tiếng Việt: {len(vietnamese_df)}\")\n",
    "print(vietnamese_df.sample(3))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "0222c88e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Số lượng null trong mỗi cột:\n",
      "text        0\n",
      "label       0\n",
      "source      0\n",
      "language    0\n",
      "dtype: int64\n",
      "\n",
      "Số dòng có text null: 0\n"
     ]
    }
   ],
   "source": [
    "# Kiểm tra null\n",
    "print(\"Số lượng null trong mỗi cột:\")\n",
    "print(df.isnull().sum())\n",
    "\n",
    "# Kiểm tra chi tiết text null\n",
    "null_texts = df[df['text'].isnull()]\n",
    "print(f\"\\nSố dòng có text null: {len(null_texts)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "33ac0ae0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Số comments trống: 0\n",
      "Sau khi loại text trống: 164069 dòng\n"
     ]
    }
   ],
   "source": [
    "# Kiểm tra text rỗng (chỉ có khoảng trắng)\n",
    "empty_texts = df[df['text'].str.strip() == '']\n",
    "print(f\"Số comments trống: {len(empty_texts)}\")\n",
    "\n",
    "# Loại bỏ\n",
    "df = df[df['text'].str.strip() != '']\n",
    "print(f\"Sau khi loại text trống: {len(df)} dòng\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "9805fa05",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Độ dài ngắn nhất: 6\n",
      "Độ dài dài nhất: 5000\n",
      "Độ dài trung bình: 385.9\n",
      "\n",
      "Số comments < 5 ký tự: 0\n",
      "\n",
      "Ví dụ:\n",
      "Series([], Name: text, dtype: object)\n"
     ]
    }
   ],
   "source": [
    "# Xem phân bố độ dài\n",
    "df['text_length'] = df['text'].str.len()\n",
    "print(f\"\\nĐộ dài ngắn nhất: {df['text_length'].min()}\")\n",
    "print(f\"Độ dài dài nhất: {df['text_length'].max()}\")\n",
    "print(f\"Độ dài trung bình: {df['text_length'].mean():.1f}\")\n",
    "\n",
    "# Xem những comments quá ngắn\n",
    "very_short = df[df['text_length'] < 5]\n",
    "print(f\"\\nSố comments < 5 ký tự: {len(very_short)}\")\n",
    "print(\"\\nVí dụ:\")\n",
    "print(very_short['text'].head(10))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "2fd8ff1e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sau khi loại comments < 10 ký tự: 164064 dòng\n"
     ]
    }
   ],
   "source": [
    "# Quyết định threshold (ví dụ: >= 10 ký tự)\n",
    "MIN_LENGTH = 10\n",
    "df = df[df['text_length'] >= MIN_LENGTH]\n",
    "print(f\"Sau khi loại comments < {MIN_LENGTH} ký tự: {len(df)} dòng\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "ea73717e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Số comments bị duplicate: 0\n"
     ]
    }
   ],
   "source": [
    "# Kiểm tra duplicates\n",
    "duplicates = df.duplicated(subset=['text'])\n",
    "print(f\"Số comments bị duplicate: {duplicates.sum()}\")\n",
    "\n",
    "# Xem ví dụ\n",
    "if duplicates.sum() > 0:\n",
    "    dup_examples = df[df.duplicated(subset=['text'], keep=False)].sort_values('text')\n",
    "    print(\"\\nVí dụ duplicates:\")\n",
    "    print(dup_examples[['text', 'label', 'source']].head(10))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "11bf39c1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Tổng số dòng cuối cùng: 164064\n"
     ]
    }
   ],
   "source": [
    "# Reset index sau khi đã xóa nhiều dòng\n",
    "df = df.reset_index(drop=True)\n",
    "print(f\"\\nTổng số dòng cuối cùng: {len(df)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "a76cbeec",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trước khi lowercase:\n",
      "Explanation\n",
      "Why the edits made under my username Hardcore Metallica Fan were reverted? They weren't vandalisms, just closure on some GAs after I voted at New York Dolls FAC. And please don't remove the template from the talk page since I'm retired now.89.205.38.27\n",
      "\n",
      "Sau khi lowercase:\n",
      "explanation\n",
      "why the edits made under my username hardcore metallica fan were reverted? they weren't vandalisms, just closure on some gas after i voted at new york dolls fac. and please don't remove the template from the talk page since i'm retired now.89.205.38.27\n"
     ]
    }
   ],
   "source": [
    "# Xem trước và sau\n",
    "print(\"Trước khi lowercase:\")\n",
    "print(df['text'].iloc[0])\n",
    "\n",
    "df['text'] = df['text'].str.lower()\n",
    "\n",
    "print(\"\\nSau khi lowercase:\")\n",
    "print(df['text'].iloc[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "d96acc68",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trước: xem video này http://youtube.com/abc hay lắm\n",
      "Sau: xem video này  hay lắm\n"
     ]
    }
   ],
   "source": [
    "import re\n",
    "\n",
    "# Hàm loại bỏ URLs\n",
    "def remove_urls(text):\n",
    "    # Pattern cho URLs\n",
    "    url_pattern = r'http\\S+|www\\.\\S+|https\\S+'\n",
    "    text = re.sub(url_pattern, '', text)\n",
    "    return text\n",
    "\n",
    "# Test trước\n",
    "test_text = \"xem video này http://youtube.com/abc hay lắm\"\n",
    "print(f\"Trước: {test_text}\")\n",
    "print(f\"Sau: {remove_urls(test_text)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "6f313d73",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Chỉ áp dụng cho tiếng Việt\n",
    "vietnamese_mask = df['language'] == 'vi'\n",
    "df.loc[vietnamese_mask, 'text'] = df.loc[vietnamese_mask, 'text'].apply(remove_urls)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "24801d7f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trước: @admin xin chào @user123 bạn ơi\n",
      "Sau:  xin chào  bạn ơi\n"
     ]
    }
   ],
   "source": [
    "def remove_mentions(text):\n",
    "    # Pattern: @ theo sau bởi ký tự chữ/số\n",
    "    mention_pattern = r'@\\w+'\n",
    "    text = re.sub(mention_pattern, '', text)\n",
    "    return text\n",
    "\n",
    "# Test\n",
    "test_text = \"@admin xin chào @user123 bạn ơi\"\n",
    "print(f\"Trước: {test_text}\")\n",
    "print(f\"Sau: {remove_mentions(test_text)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "2ab71a4f",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.loc[vietnamese_mask, 'text'] = df.loc[vietnamese_mask, 'text'].apply(remove_mentions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "5dacab48",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trước: bài này #toxic #spam quá\n",
      "Sau: bài này toxic spam quá\n"
     ]
    }
   ],
   "source": [
    "def process_hashtags(text):\n",
    "    # Loại bỏ # nhưng GIỮ text\n",
    "    # #toxic → toxic\n",
    "    hashtag_pattern = r'#(\\w+)'\n",
    "    text = re.sub(hashtag_pattern, r'\\1', text)\n",
    "    return text\n",
    "\n",
    "# Test\n",
    "test_text = \"bài này #toxic #spam quá\"\n",
    "print(f\"Trước: {test_text}\")\n",
    "print(f\"Sau: {process_hashtags(test_text)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "9a629144",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.loc[vietnamese_mask, 'text'] = df.loc[vietnamese_mask, 'text'].apply(process_hashtags)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "a008bd32",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trước: liên hệ tôi qua email abc@gmail.com nhé\n",
      "Sau: liên hệ tôi qua email  nhé\n"
     ]
    }
   ],
   "source": [
    "def remove_emails(text):\n",
    "    email_pattern = r'\\S+@\\S+\\.\\S+'\n",
    "    text = re.sub(email_pattern, '', text)\n",
    "    return text\n",
    "\n",
    "# Test\n",
    "test_text = \"liên hệ tôi qua email abc@gmail.com nhé\"\n",
    "print(f\"Trước: {test_text}\")\n",
    "print(f\"Sau: {remove_emails(test_text)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "6fbdf657",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.loc[vietnamese_mask, 'text'] = df.loc[vietnamese_mask, 'text'].apply(remove_emails)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "5206ed8d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trước: 'text   này    có     nhiều      spaces'\n",
      "Sau: 'text này có nhiều spaces'\n"
     ]
    }
   ],
   "source": [
    "def normalize_whitespace(text):\n",
    "    # Thay nhiều spaces bằng 1 space\n",
    "    text = re.sub(r'\\s+', ' ', text)\n",
    "    # Loại bỏ space đầu/cuối\n",
    "    text = text.strip()\n",
    "    return text\n",
    "\n",
    "# Test\n",
    "test_text = \"text   này    có     nhiều      spaces\"\n",
    "print(f\"Trước: '{test_text}'\")\n",
    "print(f\"Sau: '{normalize_whitespace(test_text)}'\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "651a10e1",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.loc[vietnamese_mask, 'text'] = df.loc[vietnamese_mask, 'text'].apply(normalize_whitespace)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "6fe3c9da",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trước: waaaaaa đẹpppppp quáááááá\n",
      "Sau: waa đẹpp quáá\n"
     ]
    }
   ],
   "source": [
    "def remove_repeated_chars(text):\n",
    "    # \"hayyyyyyy\" → \"hayy\" (giữ tối đa 2 ký tự lặp)\n",
    "    text = re.sub(r'(.)\\1{2,}', r'\\1\\1', text)\n",
    "    return text\n",
    "\n",
    "# Test\n",
    "test_text = \"waaaaaa đẹpppppp quáááááá\"\n",
    "print(f\"Trước: {test_text}\")\n",
    "print(f\"Sau: {remove_repeated_chars(test_text)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "d3c03dc7",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.loc[vietnamese_mask, 'text'] = df.loc[vietnamese_mask, 'text'].apply(remove_repeated_chars)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "0aa61b1c",
   "metadata": {},
   "outputs": [],
   "source": [
    "import emoji\n",
    "\n",
    "def remove_emoji_v2(text):\n",
    "    \"\"\"\n",
    "    Loại bỏ emoji sử dụng thư viện emoji\n",
    "    Phương pháp này toàn diện hơn regex\n",
    "    \"\"\"\n",
    "    # Thay thế tất cả emoji bằng chuỗi rỗng\n",
    "    return emoji.replace_emoji(text, replace='')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "100a1bdc",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.loc[vietnamese_mask, 'text'] = df.loc[vietnamese_mask, 'text'].apply(remove_emoji_v2)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bd06ae2b",
   "metadata": {},
   "source": [
    "Xử lý teecode\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "794dc50d",
   "metadata": {},
   "outputs": [],
   "source": [
    "teencode_dict = {\n",
    "    # Phủ định\n",
    "    'ko': 'không', 'k': 'không', 'khong': 'không', 'hok': 'không',\n",
    "    'kh': 'không', 'hong': 'không', 'hông': 'không',\n",
    "    \n",
    "    # Đồng ý\n",
    "    'ok': 'được', 'oke': 'được', 'okie': 'được', 'okela': 'được',\n",
    "    'dc': 'được', 'đc': 'được',\n",
    "    \n",
    "    # Đại từ\n",
    "    'mik': 'mình', 'mk': 'mình', 'mjk': 'mình',\n",
    "    'vs': 'với', 'v': 'vậy', 'z': 'vậy', 'vay': 'vậy',\n",
    "    \n",
    "    # Từ thông dụng\n",
    "    'bik': 'biết', 'bit': 'biết', 'biet': 'biết',\n",
    "    'wa': 'quá', 'wá': 'quá', 'qua': 'quá',\n",
    "    'j': 'gì', 'gi': 'gì',\n",
    "    'lm': 'làm', 'lam': 'làm',\n",
    "    'ms': 'mới', 'moi': 'mới',\n",
    "    'r': 'rồi', 'rui': 'rồi', 'ròi': 'rồi',\n",
    "    'cx': 'cũng', 'cug': 'cũng',\n",
    "    'th': 'thì', 'thi': 'thì',\n",
    "    \n",
    "    # Toxic (GIỮ CẢ HAI - quan trọng!)\n",
    "    'vcl': 'vãi cả lồn',\n",
    "    'vl': 'vãi lồn',\n",
    "    'dm': 'địt mẹ',\n",
    "    'dmm': 'địt mẹ mày',\n",
    "    'đm': 'địt mẹ',\n",
    "    'cc': 'cặc',\n",
    "    'dcm': 'địt con mẹ',\n",
    "    'đcm': 'địt con mẹ',\n",
    "    'clm': 'cái lồn mẹ',\n",
    "    'cmm': 'con mẹ mày',\n",
    "    'cmn': 'con mẹ nó',\n",
    "    'đ': 'đéo',\n",
    "    'wtf': 'what_the_fuck',\n",
    "    'loz': 'lồn'\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "6b66caab",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trước: thằng ngu vcl dm\n",
      "Sau: thằng ngu vcl vãi cả lồn dm địt mẹ\n"
     ]
    }
   ],
   "source": [
    "def expand_teencode(text, teencode_dict):\n",
    "    \"\"\"\n",
    "    Mở rộng teencode - GIỮ cả gốc và full\n",
    "    Ví dụ: \"ngu vcl\" → \"ngu vcl vãi_cái_lồn\"\n",
    "    \"\"\"\n",
    "    words = text.split()\n",
    "    expanded_words = []\n",
    "    \n",
    "    for word in words:\n",
    "        # Luôn giữ từ gốc\n",
    "        expanded_words.append(word)\n",
    "        \n",
    "        # Nếu là teencode, thêm từ đầy đủ\n",
    "        if word in teencode_dict:\n",
    "            full_word = teencode_dict[word]\n",
    "            expanded_words.append(full_word)\n",
    "    \n",
    "    return ' '.join(expanded_words)\n",
    "# Test\n",
    "test_text = \"thằng ngu vcl dm\"\n",
    "result = expand_teencode(test_text, teencode_dict)\n",
    "print(f\"Trước: {test_text}\")\n",
    "print(f\"Sau: {result}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "2576dc3d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ Đã expand teencode\n"
     ]
    }
   ],
   "source": [
    "vietnamese_mask = df['language'] == 'vi'\n",
    "df.loc[vietnamese_mask, 'text'] = df.loc[vietnamese_mask, 'text'].apply(\n",
    "    lambda x: expand_teencode(x, teencode_dict)\n",
    ")\n",
    "\n",
    "print(\"✅ Đã expand teencode\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "414b229f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "============================================================\n",
      "KIỂM TRA VÀ XỬ LÝ DỮ LIỆU (ĐÃ SỬA LỖI)\n",
      "============================================================\n",
      "Tổng số documents ban đầu: 164,064\n",
      "\n",
      "1. Kiểm tra null values: 0\n",
      "\n",
      "2. Kiểm tra empty strings: 2\n",
      "   ⚠️ Tìm thấy 2 empty strings!\n",
      "   🔧 Đang loại bỏ...\n",
      "   ✅ Đã loại bỏ. Còn lại: 164,062 documents\n",
      "\n",
      "3. Kiểm tra độ dài < 5 ký tự: 0\n",
      "\n",
      "✅ Dữ liệu đã sạch!\n",
      "   • X_text: 164,062 documents\n",
      "   • y: 164,062 labels\n",
      "   • Toxic: 16,748 (10.2%)\n",
      "   • Non-toxic: 147,314 (89.8%)\n"
     ]
    }
   ],
   "source": [
    "\n",
    "\n",
    "print(\"=\"*60)\n",
    "print(\"KIỂM TRA VÀ XỬ LÝ DỮ LIỆU (ĐÃ SỬA LỖI)\")\n",
    "print(\"=\"*60)\n",
    "\n",
    "# Bắt đầu với df từ cell trước (164,064 dòng)\n",
    "print(f\"Tổng số documents ban đầu: {len(df):,}\")\n",
    "\n",
    "# 1. Kiểm tra null/NaN \n",
    "null_count = df['text'].isnull().sum()\n",
    "print(f\"\\n1. Kiểm tra null values: {null_count}\")\n",
    "\n",
    "if null_count > 0:\n",
    "    print(f\"   ⚠️ Tìm thấy {null_count} null values!\")\n",
    "    print(f\"   🔧 Đang loại bỏ...\")\n",
    "    # Lọc TRỰC TIẾP trên df\n",
    "    df = df[df['text'].notna()].copy()\n",
    "    print(f\"   ✅ Đã loại bỏ. Còn lại: {len(df):,} documents\")\n",
    "\n",
    "# 2. Kiểm tra empty strings (từ các bước xử lý trước đó)\n",
    "empty_count = (df['text'].str.strip() == '').sum()\n",
    "print(f\"\\n2. Kiểm tra empty strings: {empty_count}\")\n",
    "\n",
    "if empty_count > 0:\n",
    "    print(f\"   ⚠️ Tìm thấy {empty_count} empty strings!\")\n",
    "    print(f\"   🔧 Đang loại bỏ...\")\n",
    "    # Lọc TRỰC TIẾP trên df\n",
    "    valid_idx = df['text'].str.strip() != ''\n",
    "    df = df[valid_idx].copy()\n",
    "    print(f\"   ✅ Đã loại bỏ. Còn lại: {len(df):,} documents\")\n",
    "\n",
    "# 3. Kiểm tra độ dài tối thiểu \n",
    "# Đặt một ngưỡng tối thiểu, ví dụ 5 ký tự\n",
    "MIN_LEN_FINAL = 5\n",
    "short_count = (df['text'].str.len() < MIN_LEN_FINAL).sum()\n",
    "print(f\"\\n3. Kiểm tra độ dài < {MIN_LEN_FINAL} ký tự: {short_count}\")\n",
    "\n",
    "if short_count > 0:\n",
    "    print(f\"   ⚠️ Có {short_count} comments < {MIN_LEN_FINAL} ký tự\")\n",
    "    print(f\"   🔧 Đang loại bỏ...\")\n",
    "    # Lọc TRỰC TIẾP trên df\n",
    "    valid_idx = df['text'].str.len() >= MIN_LEN_FINAL\n",
    "    df = df[valid_idx].copy()\n",
    "    print(f\"   ✅ Đã loại bỏ. Còn lại: {len(df):,} documents\")\n",
    "\n",
    "# Reset index một lần DUY NHẤT sau khi đã lọc xong\n",
    "df = df.reset_index(drop=True)\n",
    "\n",
    "# Gán X_text và y TỪ df đã sạch\n",
    "X_text = df['text']\n",
    "y = df['label']\n",
    "\n",
    "print(f\"\\n✅ Dữ liệu đã sạch!\")\n",
    "print(f\"   • X_text: {len(X_text):,} documents\")\n",
    "print(f\"   • y: {len(y):,} labels\")\n",
    "print(f\"   • Toxic: {(y==1).sum():,} ({(y==1).mean()*100:.1f}%)\")\n",
    "print(f\"   • Non-toxic: {(y==0).sum():,} ({(y==0).mean()*100:.1f}%)\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "647e6a45",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n"
     ]
    }
   ],
   "source": [
    "count_null = df['text'].isnull().sum()\n",
    "print(count_null)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "f4a8401c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ Đã lưu vào: ../data/cleaned_dataset.csv\n"
     ]
    }
   ],
   "source": [
    "# Lưu dữ liệu đã làm sạch\n",
    "output_file = '../data/cleaned_dataset.csv'\n",
    "df.to_csv(output_file, index=False, encoding='utf-8-sig')\n",
    "print(f\"✅ Đã lưu vào: {output_file}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "07e9096f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "================================================================================\n",
      "SO SÁNH TRƯỚC VÀ SAU XỬ LÝ\n",
      "================================================================================\n",
      "\n",
      "📊 Thống kê:\n",
      "   • Tổng số records gốc: 164,069\n",
      "   • Tổng số records sau xử lý: 164,062\n",
      "   • Số records bị loại: 7\n",
      "   • Tiếng Việt trong cleaned: 4,496\n",
      "\n",
      "🔍 TÌM CÁC MẪU CÓ THAY ĐỔI LỚN:\n",
      "================================================================================\n",
      "\n",
      "Tổng số mẫu tiếng Việt: 4,496\n",
      "\n",
      "📝 Mẫu 1:\n",
      "   Label: 🟢 Non-toxic\n",
      "   Source: youtube\n",
      "\n",
      "   📥 TRƯỚC (27 ký tự):\n",
      "      Mặt buồn thấy cưng quá hà 😂\n",
      "\n",
      "   📤 SAU (25 ký tự):\n",
      "      mặt buồn thấy cưng quá hà\n",
      "\n",
      "   🔧 Các xử lý đã áp dụng:\n",
      "      ✓ Lowercase\n",
      "      ✓ Độ dài: 27 → 25\n",
      "--------------------------------------------------------------------------------\n",
      "\n",
      "📝 Mẫu 2:\n",
      "   Label: 🟢 Non-toxic\n",
      "   Source: youtube\n",
      "\n",
      "   📥 TRƯỚC (22 ký tự):\n",
      "      Kẻ độc hành đi ad ơiii\n",
      "\n",
      "   📤 SAU (58 ký tự):\n",
      "      haha bà hiền thẩm mỹ kiểu hênh lắm mới xấu đc được z vậy á\n",
      "\n",
      "   🔧 Các xử lý đã áp dụng:\n",
      "      ✓ Lowercase\n",
      "      ✓ Độ dài: 22 → 58\n",
      "--------------------------------------------------------------------------------\n",
      "\n",
      "📝 Mẫu 3:\n",
      "   Label: 🟢 Non-toxic\n",
      "   Source: youtube\n",
      "\n",
      "   📥 TRƯỚC (117 ký tự):\n",
      "      Đúng là im lặng ngắm trò và đời!! Tụi nó vùi dập 2 thầy trò k có đường chống chế, và đây là cách đáp trả, thương Binz\n",
      "\n",
      "   📤 SAU (300 ký tự):\n",
      "      mình tua đi tua lại bài của binz nhiều lần để nghe cho đã luôn. hôm nay bin đã bùng cháy hết nỗi lòng, tình cảm của mình dành cho team & đáp trả những...\n",
      "\n",
      "   🔧 Các xử lý đã áp dụng:\n",
      "      ✓ Lowercase\n",
      "      ✓ Độ dài: 117 → 300\n",
      "--------------------------------------------------------------------------------\n",
      "\n",
      "📝 Mẫu 4:\n",
      "   Label: 🟢 Non-toxic\n",
      "   Source: vnexpress\n",
      "\n",
      "   📥 TRƯỚC (15 ký tự):\n",
      "      Chúc mừng Saka!\n",
      "\n",
      "   📤 SAU (65 ký tự):\n",
      "      có ai thấy bạn tien đâu không, tìm mãi sáng giờ mà chưa thấy. :-)\n",
      "\n",
      "   🔧 Các xử lý đã áp dụng:\n",
      "      ✓ Lowercase\n",
      "      ✓ Độ dài: 15 → 65\n",
      "--------------------------------------------------------------------------------\n",
      "\n",
      "📝 Mẫu 5:\n",
      "   Label: 🟢 Non-toxic\n",
      "   Source: vnexpress\n",
      "\n",
      "   📥 TRƯỚC (167 ký tự):\n",
      "      Những trò chơi trí tuệ như cờ vua, cờ tướng, cờ vây...cần được phổ biến rộng rãi. Khi rảnh rỗi có thứ giải trí giết thời gian thay vì lao vào các cuộc...\n",
      "\n",
      "   📤 SAU (64 ký tự):\n",
      "      một trong những nỗi sợ của các bà vợ là sợ chồng mê cờ tướng :-)\n",
      "\n",
      "   🔧 Các xử lý đã áp dụng:\n",
      "      ✓ Lowercase\n",
      "      ✓ Độ dài: 167 → 64\n",
      "--------------------------------------------------------------------------------\n",
      "\n",
      "📝 Mẫu 6:\n",
      "   Label: 🟢 Non-toxic\n",
      "   Source: youtube\n",
      "\n",
      "   📥 TRƯỚC (63 ký tự):\n",
      "      Sammy ko lo vì còn thêm antifan là phụ huynh nữa🗿 (understand?)\n",
      "\n",
      "   📤 SAU (68 ký tự):\n",
      "      sammy ko không lo vì còn thêm antifan là phụ huynh nữa (understand?)\n",
      "\n",
      "   🔧 Các xử lý đã áp dụng:\n",
      "      ✓ Lowercase\n",
      "      ✓ Độ dài: 63 → 68\n",
      "--------------------------------------------------------------------------------\n",
      "\n",
      "📝 Mẫu 7:\n",
      "   Label: 🟢 Non-toxic\n",
      "   Source: vnexpress\n",
      "\n",
      "   📥 TRƯỚC (24 ký tự):\n",
      "      Coi cái giải thua vì lít\n",
      "\n",
      "   📤 SAU (42 ký tự):\n",
      "      nhà vua của những trận giao hữu đã trở lại\n",
      "\n",
      "   🔧 Các xử lý đã áp dụng:\n",
      "      ✓ Lowercase\n",
      "      ✓ Độ dài: 24 → 42\n",
      "--------------------------------------------------------------------------------\n",
      "\n",
      "📝 Mẫu 8:\n",
      "   Label: 🟢 Non-toxic\n",
      "   Source: youtube\n",
      "\n",
      "   📥 TRƯỚC (45 ký tự):\n",
      "      Bình luận đầu nè à mà video 0 view luôn chớ:)\n",
      "\n",
      "   📤 SAU (58 ký tự):\n",
      "      giờ mới thấy càng ghét mình thì độ thành công càng cao =))\n",
      "\n",
      "   🔧 Các xử lý đã áp dụng:\n",
      "      ✓ Lowercase\n",
      "      ✓ Độ dài: 45 → 58\n",
      "--------------------------------------------------------------------------------\n",
      "\n",
      "📈 PHÂN TÍCH TỔNG QUAN:\n",
      "================================================================================\n",
      "   • Có teencode expanded (chứa _): 0\n",
      "   • Toàn lowercase: 100\n",
      "   • Có ký tự lặp ≥3 lần: 0\n",
      "   • Trung bình độ dài: 105.5 ký tự\n",
      "\n",
      "✅ Hoàn thành phân tích!\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\USER\\AppData\\Local\\Temp\\ipykernel_11284\\2420621992.py:90: UserWarning: This pattern is interpreted as a regular expression, and has match groups. To actually get the groups, use str.extract.\n",
      "  'Có ký tự lặp ≥3 lần': sample_texts.str.contains(r'(.)\\1{2,}', na=False).sum(),\n"
     ]
    }
   ],
   "source": [
    "# Load lại dữ liệu gốc để so sánh\n",
    "df_original = pd.read_csv('../data/merged_dataset.csv')\n",
    "df_cleaned = pd.read_csv('../data/cleaned_dataset.csv')\n",
    "\n",
    "print(\"=\"*80)\n",
    "print(\"SO SÁNH TRƯỚC VÀ SAU XỬ LÝ\")\n",
    "print(\"=\"*80)\n",
    "\n",
    "print(f\"\\n📊 Thống kê:\")\n",
    "print(f\"   • Tổng số records gốc: {len(df_original):,}\")\n",
    "print(f\"   • Tổng số records sau xử lý: {len(df_cleaned):,}\")\n",
    "print(f\"   • Số records bị loại: {len(df_original) - len(df_cleaned):,}\")\n",
    "print(f\"   • Tiếng Việt trong cleaned: {len(df_cleaned[df_cleaned['language'] == 'vi']):,}\")\n",
    "\n",
    "# Tìm các ví dụ có sự thay đổi rõ rệt\n",
    "print(f\"\\n🔍 TÌM CÁC MẪU CÓ THAY ĐỔI LỚN:\")\n",
    "print(\"=\"*80)\n",
    "\n",
    "# Lọc dữ liệu tiếng Việt từ cả 2 dataset\n",
    "vi_original = df_original[df_original['language'] == 'vi'].reset_index(drop=True)\n",
    "vi_cleaned = df_cleaned[df_cleaned['language'] == 'vi'].reset_index(drop=True)\n",
    "\n",
    "print(f\"\\nTổng số mẫu tiếng Việt: {len(vi_cleaned):,}\")\n",
    "\n",
    "# So sánh 10 mẫu ngẫu nhiên\n",
    "samples = vi_cleaned.sample(10, random_state=42)\n",
    "\n",
    "changes_found = 0\n",
    "for i, (idx, row) in enumerate(samples.iterrows(), 1):\n",
    "    cleaned_text = row['text']\n",
    "    \n",
    "    # Tìm text gốc tương ứng (cùng index sau reset)\n",
    "    if idx < len(vi_original):\n",
    "        original_text = vi_original.loc[idx, 'text']\n",
    "        \n",
    "        # Chỉ hiển thị nếu có thay đổi\n",
    "        if original_text.lower().strip() != cleaned_text.strip():\n",
    "            changes_found += 1\n",
    "            label = row['label']\n",
    "            source = row['source']\n",
    "            \n",
    "            print(f\"\\n📝 Mẫu {changes_found}:\")\n",
    "            print(f\"   Label: {'🔴 Toxic' if label == 1 else '🟢 Non-toxic'}\")\n",
    "            print(f\"   Source: {source}\")\n",
    "            print(f\"\\n   📥 TRƯỚC ({len(original_text)} ký tự):\")\n",
    "            if len(original_text) > 150:\n",
    "                print(f\"      {original_text[:150]}...\")\n",
    "            else:\n",
    "                print(f\"      {original_text}\")\n",
    "            \n",
    "            print(f\"\\n   📤 SAU ({len(cleaned_text)} ký tự):\")\n",
    "            if len(cleaned_text) > 150:\n",
    "                print(f\"      {cleaned_text[:150]}...\")\n",
    "            else:\n",
    "                print(f\"      {cleaned_text}\")\n",
    "            \n",
    "            # Phân tích thay đổi\n",
    "            changes = []\n",
    "            if original_text.lower() != original_text:\n",
    "                changes.append(\"✓ Lowercase\")\n",
    "            if '@' in original_text and '@' not in cleaned_text:\n",
    "                changes.append(\"✓ Loại @mentions\")\n",
    "            if 'http' in original_text and 'http' not in cleaned_text:\n",
    "                changes.append(\"✓ Loại URLs\")\n",
    "            if '_' in cleaned_text:\n",
    "                changes.append(\"✓ Expand teencode\")\n",
    "            if len(original_text) != len(cleaned_text):\n",
    "                changes.append(f\"✓ Độ dài: {len(original_text)} → {len(cleaned_text)}\")\n",
    "            \n",
    "            if changes:\n",
    "                print(f\"\\n   🔧 Các xử lý đã áp dụng:\")\n",
    "                for change in changes:\n",
    "                    print(f\"      {change}\")\n",
    "            \n",
    "            print(\"-\" * 80)\n",
    "\n",
    "if changes_found == 0:\n",
    "    print(\"\\n⚠️  Không tìm thấy thay đổi rõ rệt trong 10 mẫu ngẫu nhiên.\")\n",
    "    print(\"   Có thể do: index không tương ứng hoặc các thay đổi nhỏ\")\n",
    "\n",
    "# Phân tích tổng quan\n",
    "print(\"\\n📈 PHÂN TÍCH TỔNG QUAN:\")\n",
    "print(\"=\"*80)\n",
    "\n",
    "sample_texts = df_cleaned[df_cleaned['language'] == 'vi']['text'].head(100)\n",
    "\n",
    "patterns_found = {\n",
    "    'Có teencode expanded (chứa _)': sample_texts.str.contains('_', na=False).sum(),\n",
    "    'Toàn lowercase': sample_texts.str.islower().sum(),\n",
    "    'Có ký tự lặp ≥3 lần': sample_texts.str.contains(r'(.)\\1{2,}', na=False).sum(),\n",
    "    'Trung bình độ dài': f\"{sample_texts.str.len().mean():.1f} ký tự\"\n",
    "}\n",
    "\n",
    "for key, value in patterns_found.items():\n",
    "    print(f\"   • {key}: {value}\")\n",
    "\n",
    "print(\"\\n✅ Hoàn thành phân tích!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c2983a51",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
